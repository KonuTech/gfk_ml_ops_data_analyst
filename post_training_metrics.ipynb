{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scripts.python.get_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_PATH=\"input\"\n",
    "OUTPUT_PATH=\"output\"\n",
    "CONFIG_PATH=\"config\"\n",
    "\n",
    "INPUT_DATA=\"test_data2\"\n",
    "INPUT_DATA_CONFIG=\"input_config\"\n",
    "OUTPUT_DATA=\"output\"\n",
    "\n",
    "INPUT_EXTENSION=\"csv\"\n",
    "INPUT_CONFIG_EXTENSION=\"json\"\n",
    "OUTPUT_EXTENSION=\"csv\"\n",
    "\n",
    "INPUT_FILE=f\"{INPUT_DATA}.{INPUT_EXTENSION}\"\n",
    "INPUT_CONFIG_FILE=f\"{INPUT_DATA_CONFIG}.{INPUT_CONFIG_EXTENSION}\"\n",
    "OUTPUT_FILE=f\"{OUTPUT_DATA}.{OUTPUT_EXTENSION}\"\n",
    "\n",
    "INPUT_ABS_APTH=os.path.abspath(os.path.join(INPUT_PATH, INPUT_FILE))\n",
    "INPUT_FILE_CONFIG=os.path.abspath(os.path.join(CONFIG_PATH, INPUT_CONFIG_FILE))\n",
    "OUTPUT_ABS_APTH=os.path.abspath(os.path.join(OUTPUT_PATH, OUTPUT_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(INPUT_FILE_CONFIG, encoding='utf-8') as f:\n",
    "    CONFIG = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INPUTS': {'FILE_NAME': ['test_data2.csv'],\n",
       "  'SEPARATOR': ',',\n",
       "  'DECIMAL': None,\n",
       "  'ENCODING': 'utf-8',\n",
       "  'FLOAT_PRECISION': 'high',\n",
       "  'INDEXES': ['period_end_date', 'translated_when'],\n",
       "  'DATE_COLUMNS': ['period_end_date', 'translated_when'],\n",
       "  'DTYPE': {'if_data_corrected': 'object',\n",
       "   'prod_gr_id': 'object',\n",
       "   'country_id_n': 'object',\n",
       "   'delivery_type_id': 'object',\n",
       "   'freq_id': 'object',\n",
       "   'retailer_id': 'object',\n",
       "   'brand_id': 'object',\n",
       "   'predict_automatch': 'float',\n",
       "   'class_acctual': 'float'},\n",
       "  'CATEGORICAL_FEATURES': ['country_id_n',\n",
       "   'prod_gr_id',\n",
       "   'retailer_id',\n",
       "   'brand_id',\n",
       "   'delivery_type_id',\n",
       "   'week_number'],\n",
       "  'COLUMNS_WITH_NAN_VALUES': [None]},\n",
       " 'MODEL': {'TARGET': 'class_acctual',\n",
       "  'PREDICTION': 'predict_automatch',\n",
       "  'DATETIME': 'translated_when'},\n",
       " 'OUTPUTS': {'NAME': [None],\n",
       "  'COLUMNS_TO_EXCLUDE': ['if_data_corrected', 'freq_id'],\n",
       "  'BREAKING_POINT_DT': '2020-11-28 00:00:00+00:00'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    INPUT_ABS_APTH,\n",
    "    sep=CONFIG['INPUTS']['SEPARATOR'],\n",
    "    encoding=CONFIG['INPUTS']['ENCODING'],\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=CONFIG['INPUTS']['DATE_COLUMNS'],\n",
    "    engine=\"c\",\n",
    "    low_memory=False,\n",
    "    skipinitialspace=True,\n",
    "    dtype=CONFIG['INPUTS']['DTYPE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19697 entries, 0 to 19696\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   period_end_date    19640 non-null  datetime64[ns, UTC]\n",
      " 1   translated_when    19697 non-null  datetime64[ns, UTC]\n",
      " 2   if_data_corrected  19697 non-null  object             \n",
      " 3   prod_gr_id         19697 non-null  object             \n",
      " 4   country_id_n       18405 non-null  object             \n",
      " 5   delivery_type_id   18362 non-null  object             \n",
      " 6   freq_id            19697 non-null  object             \n",
      " 7   retailer_id        19697 non-null  object             \n",
      " 8   brand_id           19697 non-null  object             \n",
      " 9   predict_automatch  19368 non-null  float64            \n",
      " 10  class_acctual      19697 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['translated_when'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_end_date</th>\n",
       "      <th>translated_when</th>\n",
       "      <th>if_data_corrected</th>\n",
       "      <th>prod_gr_id</th>\n",
       "      <th>country_id_n</th>\n",
       "      <th>delivery_type_id</th>\n",
       "      <th>freq_id</th>\n",
       "      <th>retailer_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>predict_automatch</th>\n",
       "      <th>class_acctual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19640</td>\n",
       "      <td>19697</td>\n",
       "      <td>19697</td>\n",
       "      <td>19697</td>\n",
       "      <td>18405</td>\n",
       "      <td>18362</td>\n",
       "      <td>19697</td>\n",
       "      <td>19697</td>\n",
       "      <td>19697</td>\n",
       "      <td>19368.000000</td>\n",
       "      <td>19697.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>914</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>426</td>\n",
       "      <td>121</td>\n",
       "      <td>31480</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17085</td>\n",
       "      <td>11844</td>\n",
       "      <td>4153</td>\n",
       "      <td>998</td>\n",
       "      <td>11934</td>\n",
       "      <td>1197</td>\n",
       "      <td>587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2020-10-14 23:30:22.729124096+00:00</td>\n",
       "      <td>2020-10-22 06:01:21.525206784+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636307</td>\n",
       "      <td>0.743210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-08-30 00:00:00+00:00</td>\n",
       "      <td>2020-09-01 03:05:51+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2020-09-27 00:00:00+00:00</td>\n",
       "      <td>2020-09-29 13:45:29+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020-10-18 00:00:00+00:00</td>\n",
       "      <td>2020-10-22 04:30:49+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020-11-08 00:00:00+00:00</td>\n",
       "      <td>2020-11-13 11:57:53+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020-12-01 00:00:00+00:00</td>\n",
       "      <td>2021-02-01 14:50:49+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481074</td>\n",
       "      <td>0.436874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            period_end_date  \\\n",
       "count                                 19640   \n",
       "unique                                  NaN   \n",
       "top                                     NaN   \n",
       "freq                                    NaN   \n",
       "mean    2020-10-14 23:30:22.729124096+00:00   \n",
       "min               2020-08-30 00:00:00+00:00   \n",
       "25%               2020-09-27 00:00:00+00:00   \n",
       "50%               2020-10-18 00:00:00+00:00   \n",
       "75%               2020-11-08 00:00:00+00:00   \n",
       "max               2020-12-01 00:00:00+00:00   \n",
       "std                                     NaN   \n",
       "\n",
       "                            translated_when if_data_corrected prod_gr_id  \\\n",
       "count                                 19697             19697      19697   \n",
       "unique                                  NaN                 2          3   \n",
       "top                                     NaN                 0        426   \n",
       "freq                                    NaN             17085      11844   \n",
       "mean    2020-10-22 06:01:21.525206784+00:00               NaN        NaN   \n",
       "min               2020-09-01 03:05:51+00:00               NaN        NaN   \n",
       "25%               2020-09-29 13:45:29+00:00               NaN        NaN   \n",
       "50%               2020-10-22 04:30:49+00:00               NaN        NaN   \n",
       "75%               2020-11-13 11:57:53+00:00               NaN        NaN   \n",
       "max               2021-02-01 14:50:49+00:00               NaN        NaN   \n",
       "std                                     NaN               NaN        NaN   \n",
       "\n",
       "       country_id_n delivery_type_id freq_id retailer_id brand_id  \\\n",
       "count         18405            18362   19697       19697    19697   \n",
       "unique           34              914       2          52      199   \n",
       "top             121            31480       2          30       33   \n",
       "freq           4153              998   11934        1197      587   \n",
       "mean            NaN              NaN     NaN         NaN      NaN   \n",
       "min             NaN              NaN     NaN         NaN      NaN   \n",
       "25%             NaN              NaN     NaN         NaN      NaN   \n",
       "50%             NaN              NaN     NaN         NaN      NaN   \n",
       "75%             NaN              NaN     NaN         NaN      NaN   \n",
       "max             NaN              NaN     NaN         NaN      NaN   \n",
       "std             NaN              NaN     NaN         NaN      NaN   \n",
       "\n",
       "        predict_automatch  class_acctual  \n",
       "count        19368.000000   19697.000000  \n",
       "unique                NaN            NaN  \n",
       "top                   NaN            NaN  \n",
       "freq                  NaN            NaN  \n",
       "mean             0.636307       0.743210  \n",
       "min              0.000000       0.000000  \n",
       "25%              0.000000       0.000000  \n",
       "50%              1.000000       1.000000  \n",
       "75%              1.000000       1.000000  \n",
       "max              1.000000       1.000000  \n",
       "std              0.481074       0.436874  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(\n",
    "    include='all',\n",
    "    datetime_is_numeric=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: period_end_date\n",
      "\n",
      "                           count\n",
      "period_end_date                 \n",
      "2020-12-01 00:00:00+00:00      3\n",
      "2020-11-29 00:00:00+00:00    241\n",
      "2020-11-22 00:00:00+00:00   2192\n",
      "2020-11-15 00:00:00+00:00   1775\n",
      "2020-11-08 00:00:00+00:00    966\n",
      "2020-11-01 00:00:00+00:00   2063\n",
      "2020-10-25 00:00:00+00:00   1373\n",
      "2020-10-18 00:00:00+00:00   1442\n",
      "2020-10-11 00:00:00+00:00   1296\n",
      "2020-10-04 00:00:00+00:00   1218\n",
      "2020-10-01 00:00:00+00:00    945\n",
      "2020-09-27 00:00:00+00:00   1341\n",
      "2020-09-20 00:00:00+00:00   1025\n",
      "2020-09-13 00:00:00+00:00   1242\n",
      "2020-09-06 00:00:00+00:00   1339\n",
      "2020-09-01 00:00:00+00:00    876\n",
      "2020-08-30 00:00:00+00:00    303\n",
      "\n",
      "\n",
      "COLUMN: translated_when\n",
      "\n",
      "                           count\n",
      "translated_when                 \n",
      "2021-02-01 14:50:49+00:00      1\n",
      "2021-01-29 09:56:17+00:00      1\n",
      "2021-01-28 13:48:19+00:00      1\n",
      "2021-01-28 10:44:57+00:00      1\n",
      "2021-01-27 17:35:47+00:00      1\n",
      "...                          ...\n",
      "2020-09-01 06:15:50+00:00      1\n",
      "2020-09-01 06:15:32+00:00      1\n",
      "2020-09-01 03:44:29+00:00      1\n",
      "2020-09-01 03:35:26+00:00      1\n",
      "2020-09-01 03:05:51+00:00      1\n",
      "\n",
      "[15628 rows x 1 columns]\n",
      "\n",
      "\n",
      "COLUMN: if_data_corrected\n",
      "\n",
      "                   count\n",
      "if_data_corrected       \n",
      "1                   2612\n",
      "0                  17085\n",
      "\n",
      "\n",
      "COLUMN: prod_gr_id\n",
      "\n",
      "            count\n",
      "prod_gr_id       \n",
      "427          3367\n",
      "426         11844\n",
      "413          4486\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "              count\n",
      "country_id_n       \n",
      "177             110\n",
      "176            1022\n",
      "174               1\n",
      "173               1\n",
      "170               5\n",
      "160              47\n",
      "151               1\n",
      "150              10\n",
      "141               9\n",
      "139             438\n",
      "138             104\n",
      "136              29\n",
      "131              10\n",
      "128               2\n",
      "126            1354\n",
      "124               1\n",
      "121            4153\n",
      "120              26\n",
      "119               7\n",
      "118               3\n",
      "116             502\n",
      "114             693\n",
      "113            1620\n",
      "110            1125\n",
      "109             375\n",
      "108            3137\n",
      "107             357\n",
      "106             727\n",
      "105             352\n",
      "104             693\n",
      "103             881\n",
      "1011            179\n",
      "1010            416\n",
      "1002             15\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "                  count\n",
      "delivery_type_id       \n",
      "9974                  9\n",
      "9966                  1\n",
      "9949                 24\n",
      "9617                  1\n",
      "9158                  4\n",
      "...                 ...\n",
      "11553                 5\n",
      "11528               124\n",
      "11191                 2\n",
      "10741                 3\n",
      "10511                 9\n",
      "\n",
      "[914 rows x 1 columns]\n",
      "\n",
      "\n",
      "COLUMN: freq_id\n",
      "\n",
      "         count\n",
      "freq_id       \n",
      "2        11934\n",
      "1         7763\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "             count\n",
      "retailer_id       \n",
      "96             727\n",
      "95             527\n",
      "94             861\n",
      "93            1066\n",
      "92            1036\n",
      "91             313\n",
      "90             695\n",
      "9              533\n",
      "88             583\n",
      "69             386\n",
      "55             754\n",
      "49             407\n",
      "45             656\n",
      "35             189\n",
      "34             415\n",
      "33             215\n",
      "32             172\n",
      "31             477\n",
      "30            1197\n",
      "29             224\n",
      "28             387\n",
      "27              26\n",
      "26             391\n",
      "25              41\n",
      "22             360\n",
      "211            429\n",
      "210            377\n",
      "178            303\n",
      "177             73\n",
      "176            103\n",
      "175             92\n",
      "174            202\n",
      "173            268\n",
      "172            317\n",
      "145            522\n",
      "141            521\n",
      "139            260\n",
      "136             55\n",
      "134             71\n",
      "133            388\n",
      "130            196\n",
      "127            239\n",
      "124            405\n",
      "123            102\n",
      "120            207\n",
      "119            125\n",
      "118             61\n",
      "117            215\n",
      "116            111\n",
      "115             67\n",
      "11             792\n",
      "10             558\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "          count\n",
      "brand_id       \n",
      "99          527\n",
      "96          579\n",
      "95          359\n",
      "90           38\n",
      "85           40\n",
      "...         ...\n",
      "123         163\n",
      "116          98\n",
      "114          98\n",
      "111         369\n",
      "108         320\n",
      "\n",
      "[199 rows x 1 columns]\n",
      "\n",
      "\n",
      "COLUMN: predict_automatch\n",
      "\n",
      "                   count\n",
      "predict_automatch       \n",
      "1.0                12324\n",
      "0.0                 7044\n",
      "\n",
      "\n",
      "COLUMN: class_acctual\n",
      "\n",
      "               count\n",
      "class_acctual       \n",
      "1.0            14639\n",
      "0.0             5058\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clear a file\n",
    "with open('output/agg_counts.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    output = df.groupby(column) \\\n",
    "        .size() \\\n",
    "        .rename('count') \\\n",
    "        .reset_index() \\\n",
    "        .sort_values(by=column, ascending=False) \\\n",
    "        .set_index(column)\n",
    "\n",
    "    print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "    \n",
    "    # save output to log txt\n",
    "    with open('output/agg_counts.txt', 'a') as f:\n",
    "        with redirect_stdout(f):\n",
    "            print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: period_end_date\n",
      "\n",
      "                           count_total\n",
      "period_end_date                       \n",
      "2020-12-01 00:00:00+00:00            1\n",
      "2020-11-29 00:00:00+00:00          139\n",
      "2020-11-22 00:00:00+00:00         1358\n",
      "2020-11-15 00:00:00+00:00         1130\n",
      "2020-11-08 00:00:00+00:00          570\n",
      "2020-11-01 00:00:00+00:00         1291\n",
      "2020-10-25 00:00:00+00:00          885\n",
      "2020-10-18 00:00:00+00:00          908\n",
      "2020-10-11 00:00:00+00:00          805\n",
      "2020-10-04 00:00:00+00:00          744\n",
      "2020-10-01 00:00:00+00:00          632\n",
      "2020-09-27 00:00:00+00:00          822\n",
      "2020-09-20 00:00:00+00:00          642\n",
      "2020-09-13 00:00:00+00:00          764\n",
      "2020-09-06 00:00:00+00:00          807\n",
      "2020-09-01 00:00:00+00:00          577\n",
      "2020-08-30 00:00:00+00:00          209\n",
      "\n",
      "\n",
      "COLUMN: translated_when\n",
      "\n",
      "                           count_total\n",
      "translated_when                       \n",
      "2021-02-01 14:50:49+00:00            1\n",
      "2021-01-28 13:48:19+00:00            1\n",
      "2021-01-28 10:44:57+00:00            1\n",
      "2021-01-27 17:35:47+00:00            1\n",
      "2021-01-26 08:28:42+00:00            1\n",
      "...                                ...\n",
      "2020-09-01 06:15:50+00:00            1\n",
      "2020-09-01 06:15:32+00:00            1\n",
      "2020-09-01 03:44:29+00:00            1\n",
      "2020-09-01 03:35:26+00:00            1\n",
      "2020-09-01 03:05:51+00:00            1\n",
      "\n",
      "[10149 rows x 1 columns]\n",
      "\n",
      "\n",
      "COLUMN: if_data_corrected\n",
      "\n",
      "                   count_total\n",
      "if_data_corrected             \n",
      "1                         1707\n",
      "0                        10617\n",
      "\n",
      "\n",
      "COLUMN: prod_gr_id\n",
      "\n",
      "            count_total\n",
      "prod_gr_id             \n",
      "427                2235\n",
      "426                7298\n",
      "413                2791\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "              count_total\n",
      "country_id_n             \n",
      "177                    75\n",
      "176                   679\n",
      "160                    32\n",
      "139                   249\n",
      "138                    66\n",
      "136                    20\n",
      "126                   922\n",
      "121                  2699\n",
      "116                   326\n",
      "114                   477\n",
      "113                  1078\n",
      "110                   731\n",
      "109                   145\n",
      "108                  2166\n",
      "107                   240\n",
      "106                   313\n",
      "105                   236\n",
      "104                   485\n",
      "103                   627\n",
      "1011                  131\n",
      "1010                  283\n",
      "1002                   11\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "                  count_total\n",
      "delivery_type_id             \n",
      "9974                        2\n",
      "9949                        8\n",
      "9158                        3\n",
      "8705                        1\n",
      "8088                       22\n",
      "...                       ...\n",
      "1218                       19\n",
      "11553                       1\n",
      "11528                      85\n",
      "10741                       1\n",
      "10511                       7\n",
      "\n",
      "[767 rows x 1 columns]\n",
      "\n",
      "\n",
      "COLUMN: freq_id\n",
      "\n",
      "         count_total\n",
      "freq_id             \n",
      "2               7438\n",
      "1               4886\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "             count_total\n",
      "retailer_id             \n",
      "96                   446\n",
      "95                   345\n",
      "94                   537\n",
      "93                   639\n",
      "92                   694\n",
      "91                   197\n",
      "90                   433\n",
      "9                    364\n",
      "88                   400\n",
      "69                   241\n",
      "55                   455\n",
      "49                   266\n",
      "45                   427\n",
      "35                   111\n",
      "34                   280\n",
      "33                   153\n",
      "32                   110\n",
      "31                   276\n",
      "30                   702\n",
      "29                   152\n",
      "28                   259\n",
      "26                   191\n",
      "25                    24\n",
      "22                   227\n",
      "211                  258\n",
      "210                  276\n",
      "178                  161\n",
      "177                   48\n",
      "176                   44\n",
      "175                   42\n",
      "174                  144\n",
      "173                  192\n",
      "172                  196\n",
      "145                  334\n",
      "141                  336\n",
      "139                  177\n",
      "136                   24\n",
      "133                  254\n",
      "130                  129\n",
      "127                  151\n",
      "124                  273\n",
      "123                   71\n",
      "120                  135\n",
      "119                   75\n",
      "118                   42\n",
      "117                  142\n",
      "116                   67\n",
      "115                   32\n",
      "11                   416\n",
      "10                   376\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "          count_total\n",
      "brand_id             \n",
      "99                320\n",
      "96                366\n",
      "95                237\n",
      "90                 30\n",
      "85                 31\n",
      "...               ...\n",
      "123               110\n",
      "116                70\n",
      "114                59\n",
      "111               221\n",
      "108               206\n",
      "\n",
      "[196 rows x 1 columns]\n",
      "\n",
      "\n",
      "COLUMN: predict_automatch\n",
      "\n",
      "                   count_total\n",
      "predict_automatch             \n",
      "1.0                      12324\n",
      "\n",
      "\n",
      "COLUMN: class_acctual\n",
      "\n",
      "               count_total\n",
      "class_acctual             \n",
      "1.0                  11221\n",
      "0.0                   1103\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clear a file\n",
    "with open('output/agg_sum.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# get positive predictions\n",
    "data_frame = df.loc[df['predict_automatch'] == 1]\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in data_frame.columns:\n",
    "    output = data_frame.groupby(column) \\\n",
    "        .size() \\\n",
    "        .rename('count_total') \\\n",
    "        .reset_index() \\\n",
    "        .sort_values(by=column, ascending=False) \\\n",
    "        .set_index(column)\n",
    "\n",
    "    print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "    \n",
    "    # save output to log txt\n",
    "    with open('output/agg_sum.txt', 'a') as f:\n",
    "        with redirect_stdout(f):\n",
    "            print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Post-Processing Bias Metrics for the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Difference in positive proportion in predicted labels (DPPL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image info](./docs/images/metrics/DPPL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> DPPPL > -1 AND DPPPL < 1\n",
    "\n",
    "> For example, if the model grants loans to 50% of class 2 and to 60% of class 1, then it may be biased against class 2.\n",
    "We would have to decide whether a 10% difference is material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "prod_gr_id\n",
      "427    0.663796\n",
      "426    0.616177\n",
      "413    0.622158\n",
      "Name: PPL, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "country_id_n\n",
      "177     0.681818\n",
      "176     0.664384\n",
      "160     0.680851\n",
      "139     0.568493\n",
      "138     0.634615\n",
      "136     0.689655\n",
      "126     0.680945\n",
      "121     0.649892\n",
      "116     0.649402\n",
      "114     0.688312\n",
      "113     0.665432\n",
      "110     0.649778\n",
      "109     0.386667\n",
      "108     0.690469\n",
      "107     0.672269\n",
      "106     0.430536\n",
      "105     0.670455\n",
      "104     0.699856\n",
      "103     0.711691\n",
      "1011    0.731844\n",
      "1010    0.680288\n",
      "1002    0.733333\n",
      "Name: PPL, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "delivery_type_id\n",
      "9974     0.222222\n",
      "9949     0.333333\n",
      "9158     0.750000\n",
      "8705     0.500000\n",
      "8088     0.372881\n",
      "           ...   \n",
      "1218     0.558824\n",
      "11553    0.200000\n",
      "11528    0.685484\n",
      "10741    0.333333\n",
      "10511    0.777778\n",
      "Name: PPL, Length: 767, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "retailer_id\n",
      "96     0.613480\n",
      "95     0.654649\n",
      "94     0.623693\n",
      "93     0.599437\n",
      "92     0.669884\n",
      "91     0.629393\n",
      "90     0.623022\n",
      "9      0.682927\n",
      "88     0.686106\n",
      "69     0.624352\n",
      "55     0.603448\n",
      "49     0.653563\n",
      "45     0.650915\n",
      "35     0.587302\n",
      "34     0.674699\n",
      "33     0.711628\n",
      "32     0.639535\n",
      "31     0.578616\n",
      "30     0.586466\n",
      "29     0.678571\n",
      "28     0.669251\n",
      "26     0.488491\n",
      "25     0.585366\n",
      "22     0.630556\n",
      "211    0.601399\n",
      "210    0.732095\n",
      "178    0.531353\n",
      "177    0.657534\n",
      "176    0.427184\n",
      "175    0.456522\n",
      "174    0.712871\n",
      "173    0.716418\n",
      "172    0.618297\n",
      "145    0.639847\n",
      "141    0.644914\n",
      "139    0.680769\n",
      "136    0.436364\n",
      "133    0.654639\n",
      "130    0.658163\n",
      "127    0.631799\n",
      "124    0.674074\n",
      "123    0.696078\n",
      "120    0.652174\n",
      "119    0.600000\n",
      "118    0.688525\n",
      "117    0.660465\n",
      "116    0.603604\n",
      "115    0.477612\n",
      "11     0.525253\n",
      "10     0.673835\n",
      "Name: PPL, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "brand_id\n",
      "99     0.607211\n",
      "96     0.632124\n",
      "95     0.660167\n",
      "90     0.789474\n",
      "85     0.775000\n",
      "         ...   \n",
      "123    0.674847\n",
      "116    0.714286\n",
      "114    0.602041\n",
      "111    0.598916\n",
      "108    0.643750\n",
      "Name: PPL, Length: 196, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/PPL.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_PPL(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count='predict_automatch'\n",
    "        )\n",
    "\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "\n",
    "        # save output to log txt\n",
    "        with open('output/PPL.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DPPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.047619\n",
      "1   -0.041638\n",
      "2   -0.005981\n",
      "3    0.005981\n",
      "4    0.041638\n",
      "5    0.047619\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.346667\n",
      "1     -0.345177\n",
      "2     -0.325025\n",
      "3     -0.313189\n",
      "4     -0.303802\n",
      "         ...   \n",
      "457    0.303802\n",
      "458    0.313189\n",
      "459    0.325025\n",
      "460    0.345177\n",
      "461    0.346667\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0       -0.909091\n",
      "1       -0.864865\n",
      "2       -0.857143\n",
      "3       -0.833333\n",
      "4       -0.812500\n",
      "           ...   \n",
      "28097    0.812500\n",
      "28098    0.833333\n",
      "28099    0.857143\n",
      "28100    0.864865\n",
      "28101    0.909091\n",
      "Length: 28102, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -0.304911\n",
      "1      -0.295732\n",
      "2      -0.289233\n",
      "3      -0.285687\n",
      "4      -0.284443\n",
      "          ...   \n",
      "2445    0.284443\n",
      "2446    0.285687\n",
      "2447    0.289233\n",
      "2448    0.295732\n",
      "2449    0.304911\n",
      "Length: 2450, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0       -0.698413\n",
      "1       -0.647059\n",
      "2       -0.615385\n",
      "3       -0.608696\n",
      "4       -0.607504\n",
      "           ...   \n",
      "24323    0.607504\n",
      "24324    0.608696\n",
      "24325    0.615385\n",
      "24326    0.647059\n",
      "24327    0.698413\n",
      "Length: 24328, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DPPL.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DPPL(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DPPL.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPPL bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.0477, -0.0159]    2\n",
      "(-0.0159, 0.0159]     2\n",
      "(0.0159, 0.0476]      2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-0.347, -0.116]     47\n",
      "(-0.116, 0.116]     368\n",
      "(0.116, 0.347]       47\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(-0.911, -0.303]     2480\n",
      "(-0.303, 0.303]     23143\n",
      "(0.303, 0.909]       2479\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-0.306, -0.102]     319\n",
      "(-0.102, 0.102]     1812\n",
      "(0.102, 0.305]       319\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-0.7, -0.233]      1398\n",
      "(-0.233, 0.233]    21532\n",
      "(0.233, 0.698]      1398\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DPPL_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DPPL(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DPPL_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> Basing solely on **DPPL** we can loosely assume that there is no disparity impact among **prod_gr_id** Classes\n",
    ">\n",
    "> Although it is likely. Basing solely on **DPPL** we can't assume if there is a disparity impact among **prod_gr_id** Classes yet. \n",
    ">\n",
    "> TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Disparate (Adverse) Impact (DI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image info](./docs/images/metrics/DI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> **DI >= 0**\n",
    "\n",
    "> This measure may be considered fair if it resides in the **<0.8; 1.2>** range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0    0.928263\n",
      "1    0.937273\n",
      "2    0.990387\n",
      "3    1.009706\n",
      "4    1.066925\n",
      "5    1.077281\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0      0.527273\n",
      "1      0.528346\n",
      "2      0.543307\n",
      "3      0.552495\n",
      "4      0.560006\n",
      "         ...   \n",
      "457    1.785695\n",
      "458    1.809972\n",
      "459    1.840581\n",
      "460    1.892699\n",
      "461    1.896552\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0          0.090909\n",
      "1          0.090909\n",
      "2          0.090909\n",
      "3          0.090909\n",
      "4          0.090909\n",
      "            ...    \n",
      "521475    11.000000\n",
      "521476    11.000000\n",
      "521477    11.000000\n",
      "521478    11.000000\n",
      "521479    11.000000\n",
      "Length: 521480, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0       0.583509\n",
      "1       0.596047\n",
      "2       0.596278\n",
      "3       0.599245\n",
      "4       0.600292\n",
      "          ...   \n",
      "2445    1.665856\n",
      "2446    1.668767\n",
      "2447    1.677069\n",
      "2448    1.677719\n",
      "2449    1.713769\n",
      "Length: 2450, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0        0.301587\n",
      "1        0.301587\n",
      "2        0.301587\n",
      "3        0.331746\n",
      "4        0.339286\n",
      "           ...   \n",
      "38081    2.947368\n",
      "38082    3.014354\n",
      "38083    3.315789\n",
      "38084    3.315789\n",
      "38085    3.315789\n",
      "Length: 38086, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DI.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_PPL(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        di_output = sorted([(i / j) for i in output for j in output if i != j])\n",
    "        \n",
    "        di_output = pd.Series(di_output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{di_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DI.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{di_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DI bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(0.928, 0.978]    2\n",
      "(0.978, 1.028]    2\n",
      "(1.028, 1.077]    2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(0.526, 0.984]    191\n",
      "(0.984, 1.44]     232\n",
      "(1.44, 1.897]      39\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(0.08, 3.727]     512863\n",
      "(3.727, 7.364]      7966\n",
      "(7.364, 11.0]        651\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(0.582, 0.96]      918\n",
      "(0.96, 1.337]     1358\n",
      "(1.337, 1.714]     174\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(0.299, 1.306]    33916\n",
      "(1.306, 2.311]     4099\n",
      "(2.311, 3.316]       71\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DI_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_PPL(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        di_output = sorted([(i / j) for i in output for j in output if i != j])\n",
    "        \n",
    "        bucketized_output = pd.cut(di_output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DI_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> For each possible relation between Classes the metric resides between **<0.8; 1.2>**\n",
    "\n",
    "> We can loosely assume that there is no disparity impact between Classes of **prod_gr_id** Variable\n",
    "\n",
    "> At this moment we can loosely assume that there are some examples of Disparity Impact in case of **country_id_n** Variable.\n",
    "\n",
    "> Seems like **DI** tries to tell that distributions between countrie **106** and **1011** are diffrent from each other. If that is true I would recommend reducing dimmensionality by feature engineering. I would use **WoE** (**Weight of Evidence**) to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Dividing Ratios by Ratios, so values close to 1 are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Difference in Conditional Outcome (DCO)\n",
    "> Type 1: **Difference in Conditional Acceptance (DCA)**\n",
    "\n",
    "> Type 2: **Difference in Conditional Rejection (DCR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> When both **DCA** and **DCR** are very close to **0**, we can conclude that the proportion of qualified (as suggested by observed labels) applicants accepted by the model and the proportion of unqualified applicants rejected are nearly equal across both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Difference in Conditional Acceptance (DCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image info](./docs/images/metrics/DCA.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> Unbounded\n",
    "\n",
    "> Zero denominator is possible. In such case the allocations to each Class are too small and a warning should be issued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "prod_gr_id\n",
      "427    1.114989\n",
      "426    1.203069\n",
      "413    1.206378\n",
      "Name: CA, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "country_id_n\n",
      "177     1.040000\n",
      "176     1.120766\n",
      "160     1.031250\n",
      "139     1.317269\n",
      "138     1.212121\n",
      "136     1.050000\n",
      "126     1.090022\n",
      "121     1.133012\n",
      "116     1.147239\n",
      "114     1.085954\n",
      "113     1.123377\n",
      "110     1.136799\n",
      "109     2.000000\n",
      "108     1.072022\n",
      "107     1.079167\n",
      "106     1.686901\n",
      "105     1.105932\n",
      "104     1.045361\n",
      "103     1.063796\n",
      "1011    1.091603\n",
      "1010    1.116608\n",
      "1002    1.090909\n",
      "Name: CA, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "delivery_type_id\n",
      "9974     3.500000\n",
      "9949     2.000000\n",
      "9158     1.333333\n",
      "8705     2.000000\n",
      "8088     2.227273\n",
      "           ...   \n",
      "1218     1.157895\n",
      "11553    4.000000\n",
      "11528    1.164706\n",
      "10741    2.000000\n",
      "10511    1.142857\n",
      "Name: CA, Length: 749, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "retailer_id\n",
      "96     1.233184\n",
      "95     1.107246\n",
      "94     1.189944\n",
      "93     1.220657\n",
      "92     1.121037\n",
      "91     1.131980\n",
      "90     1.182448\n",
      "9      1.087912\n",
      "88     1.102500\n",
      "69     1.132780\n",
      "55     1.239560\n",
      "49     1.150376\n",
      "45     1.131148\n",
      "35     1.261261\n",
      "34     1.121429\n",
      "33     1.052288\n",
      "32     1.200000\n",
      "31     1.311594\n",
      "30     1.213675\n",
      "29     1.138158\n",
      "28     1.123552\n",
      "26     1.554974\n",
      "25     1.041667\n",
      "22     1.171806\n",
      "211    1.166667\n",
      "210    1.097826\n",
      "178    1.285714\n",
      "177    1.187500\n",
      "176    1.636364\n",
      "175    1.619048\n",
      "174    1.125000\n",
      "173    1.067708\n",
      "172    1.163265\n",
      "145    1.167665\n",
      "141    1.214286\n",
      "139    1.079096\n",
      "136    1.625000\n",
      "133    1.157480\n",
      "130    1.178295\n",
      "127    1.172185\n",
      "124    1.124542\n",
      "123    1.154930\n",
      "120    1.140741\n",
      "119    1.133333\n",
      "118    1.071429\n",
      "117    1.105634\n",
      "116    1.194030\n",
      "115    1.593750\n",
      "11     1.423077\n",
      "10     1.109043\n",
      "Name: CA, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "brand_id\n",
      "99     1.200000\n",
      "96     1.150273\n",
      "95     1.147679\n",
      "90     1.000000\n",
      "85     1.129032\n",
      "         ...   \n",
      "123    1.100000\n",
      "116    1.000000\n",
      "114    1.338983\n",
      "111    1.235294\n",
      "108    1.150485\n",
      "Name: CA, Length: 196, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/CA.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_CA(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/CA.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.091389\n",
      "1   -0.088081\n",
      "2   -0.003308\n",
      "3    0.003308\n",
      "4    0.088081\n",
      "5    0.091389\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.968750\n",
      "1     -0.960000\n",
      "2     -0.954639\n",
      "3     -0.950000\n",
      "4     -0.936204\n",
      "         ...   \n",
      "457    0.936204\n",
      "458    0.950000\n",
      "459    0.954639\n",
      "460    0.960000\n",
      "461    0.968750\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0       -9.666667\n",
      "1       -9.500000\n",
      "2       -9.333333\n",
      "3       -9.285714\n",
      "4       -9.250000\n",
      "           ...   \n",
      "21523    9.250000\n",
      "21524    9.285714\n",
      "21525    9.333333\n",
      "21526    9.500000\n",
      "21527    9.666667\n",
      "Length: 21528, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -0.594697\n",
      "1      -0.584076\n",
      "2      -0.583333\n",
      "3      -0.577381\n",
      "4      -0.572712\n",
      "          ...   \n",
      "2445    0.572712\n",
      "2446    0.577381\n",
      "2447    0.583333\n",
      "2448    0.584076\n",
      "2449    0.594697\n",
      "Length: 2450, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0       -1.583333\n",
      "1       -1.500000\n",
      "2       -1.458333\n",
      "3       -1.444444\n",
      "4       -1.424242\n",
      "           ...   \n",
      "18973    1.424242\n",
      "18974    1.444444\n",
      "18975    1.458333\n",
      "18976    1.500000\n",
      "18977    1.583333\n",
      "Length: 18978, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DCA.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DCA(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DCA.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCA bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.0916, -0.0305]    2\n",
      "(-0.0305, 0.0305]     2\n",
      "(0.0305, 0.0914]      2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-0.971, -0.323]     40\n",
      "(-0.323, 0.323]     382\n",
      "(0.323, 0.969]       40\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(-9.686, -3.222]      737\n",
      "(-3.222, 3.222]     20053\n",
      "(3.222, 9.667]        738\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-0.596, -0.198]     279\n",
      "(-0.198, 0.198]     1892\n",
      "(0.198, 0.595]       279\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-1.587, -0.528]      900\n",
      "(-0.528, 0.528]     17178\n",
      "(0.528, 1.583]        900\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DCA_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DCA(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DCA_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> TODO: Diffrances are really small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Difference in Conditional Rejection (DCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image info](./docs/images/metrics/DCR.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> Unbounded\n",
    "\n",
    "> Zero denominator is possible. In such case the allocations to each Class are too small and a warning should be issued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "prod_gr_id\n",
      "427    0.784050\n",
      "426    0.716223\n",
      "413    0.678182\n",
      "Name: CR, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "country_id_n\n",
      "177     0.914286\n",
      "176     0.765396\n",
      "160     0.933333\n",
      "139     0.582011\n",
      "138     0.648649\n",
      "136     0.888889\n",
      "126     0.817330\n",
      "121     0.784384\n",
      "116     0.920863\n",
      "114     0.817757\n",
      "113     0.768797\n",
      "110     0.942308\n",
      "109     0.372807\n",
      "108     0.849844\n",
      "107     0.844828\n",
      "106     0.481840\n",
      "105     0.798246\n",
      "104     0.916256\n",
      "103     0.856000\n",
      "1011    0.765957\n",
      "1010    0.763359\n",
      "1002    0.750000\n",
      "Name: CR, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "delivery_type_id\n",
      "9974     0.285714\n",
      "9966     1.000000\n",
      "9949     0.500000\n",
      "9617     1.000000\n",
      "8632     1.000000\n",
      "           ...   \n",
      "1218     0.857143\n",
      "11553    0.250000\n",
      "11528    0.657895\n",
      "10741    0.500000\n",
      "10511    0.500000\n",
      "Name: CR, Length: 545, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "retailer_id\n",
      "96     0.638989\n",
      "95     0.801105\n",
      "94     0.691589\n",
      "93     0.671362\n",
      "92     0.763314\n",
      "91     0.782609\n",
      "90     0.701149\n",
      "9      0.825301\n",
      "88     0.780220\n",
      "69     0.790210\n",
      "55     0.641892\n",
      "49     0.721429\n",
      "45     0.762115\n",
      "35     0.680556\n",
      "34     0.753731\n",
      "33     1.000000\n",
      "32     0.701754\n",
      "31     0.575000\n",
      "30     0.831325\n",
      "29     0.718310\n",
      "28     0.761905\n",
      "26     0.479592\n",
      "25     1.000000\n",
      "22     0.712121\n",
      "211    0.766467\n",
      "210    0.740000\n",
      "178    0.680851\n",
      "177    0.761905\n",
      "176    0.885714\n",
      "175    0.615385\n",
      "174    0.689655\n",
      "173    0.851351\n",
      "172    0.735537\n",
      "145    0.702128\n",
      "141    0.617486\n",
      "139    0.851852\n",
      "136    1.000000\n",
      "134    1.500000\n",
      "133    0.712121\n",
      "130    0.656716\n",
      "127    0.712644\n",
      "124    0.759690\n",
      "123    0.714286\n",
      "120    0.746479\n",
      "119    0.833333\n",
      "118    1.066667\n",
      "117    0.794521\n",
      "116    0.815789\n",
      "115    0.695652\n",
      "11     0.537634\n",
      "10     0.779006\n",
      "Name: CR, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "brand_id\n",
      "99     0.700980\n",
      "96     0.745283\n",
      "95     0.725000\n",
      "90     1.000000\n",
      "85     0.555556\n",
      "         ...   \n",
      "123    0.807692\n",
      "116    1.000000\n",
      "114    0.703704\n",
      "111    0.662069\n",
      "108    0.734513\n",
      "Name: CR, Length: 194, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/CR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_CR(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/CR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.105868\n",
      "1   -0.067828\n",
      "2   -0.038041\n",
      "3    0.038041\n",
      "4    0.067828\n",
      "5    0.105868\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.569501\n",
      "1     -0.560526\n",
      "2     -0.548056\n",
      "3     -0.543449\n",
      "4     -0.541479\n",
      "         ...   \n",
      "457    0.541479\n",
      "458    0.543449\n",
      "459    0.548056\n",
      "460    0.560526\n",
      "461    0.569501\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0       -2.900000\n",
      "1       -2.875000\n",
      "2       -2.857143\n",
      "3       -2.843750\n",
      "4       -2.833333\n",
      "           ...   \n",
      "11923    2.833333\n",
      "11924    2.843750\n",
      "11925    2.857143\n",
      "11926    2.875000\n",
      "11927    2.900000\n",
      "Length: 11928, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -1.020408\n",
      "1      -0.962366\n",
      "2      -0.925000\n",
      "3      -0.884615\n",
      "4      -0.882514\n",
      "          ...   \n",
      "2155    0.882514\n",
      "2156    0.884615\n",
      "2157    0.925000\n",
      "2158    0.962366\n",
      "2159    1.020408\n",
      "Length: 2160, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0       -1.750000\n",
      "1       -1.636364\n",
      "2       -1.610000\n",
      "3       -1.600000\n",
      "4       -1.560976\n",
      "           ...   \n",
      "12207    1.560976\n",
      "12208    1.600000\n",
      "12209    1.610000\n",
      "12210    1.636364\n",
      "12211    1.750000\n",
      "Length: 12212, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DCR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DCR(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DCR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCR bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.106, -0.0353]    3\n",
      "(-0.0353, 0.0353]    0\n",
      "(0.0353, 0.106]      3\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-0.571, -0.19]     61\n",
      "(-0.19, 0.19]      340\n",
      "(0.19, 0.57]        61\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(-2.906, -0.967]      445\n",
      "(-0.967, 0.967]     11039\n",
      "(0.967, 2.9]          444\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-1.022, -0.34]      83\n",
      "(-0.34, 0.34]      1994\n",
      "(0.34, 1.02]         83\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-1.754, -0.583]      552\n",
      "(-0.583, 0.583]     11110\n",
      "(0.583, 1.75]         550\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DCR_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DCR(\n",
    "            data_frame=df,\n",
    "            column_to_group_by=column,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch'\n",
    "        )\n",
    "        \n",
    "        bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DCR_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall Difference (RD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./docs/images/metrics/RD.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX (by Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "  Class  TN   FN    FP    TP\n",
      "0   426  75  193  2989  8587\n",
      "1   413  11   34  1108  3333\n",
      "2   427   4   12   871  2480\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "   Class  TN  FN    FP    TP\n",
      "0    126   1   4   348  1001\n",
      "1    113   1   9   408  1202\n",
      "2    114   1   1   174   517\n",
      "3    110  25  57   269   774\n",
      "4    139   0   0   110   328\n",
      "5    108   3   9   812  2313\n",
      "6    121  17  41  1078  3017\n",
      "7    109   0   2    85   288\n",
      "8    107   0   1    98   258\n",
      "9    103   2   2   212   665\n",
      "10   106   0   1   199   527\n",
      "11   176   0   2   261   759\n",
      "12   116  11  26   117   348\n",
      "13   105   0   2    91   259\n",
      "14   104   3   2   183   505\n",
      "15   177   0   0    32    78\n",
      "16  1010   0   2   100   314\n",
      "17   136   0   0     8    21\n",
      "18   138   1   0    23    80\n",
      "19  1011   0   1    36   142\n",
      "20   160   0   0    14    33\n",
      "21   128   1   1     0     0\n",
      "22   118   1   2     0     0\n",
      "23   119   1   6     0     0\n",
      "24   131   2   8     0     0\n",
      "25   150   2   8     0     0\n",
      "26   170   1   4     0     0\n",
      "27   141   2   7     0     0\n",
      "28   124   2   7     0     0\n",
      "29  1002   0   0     3    12\n",
      "30   173   0   0     3    12\n",
      "31   151   0   1     0     0\n",
      "32   120   8  18     0     0\n",
      "33   174   0   1     0     0\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "     Class TN FN  FP  TP\n",
      "0    22866  0  0   7  20\n",
      "1    12731  0  1   1   8\n",
      "2    18614  1  0  20  50\n",
      "3    64135  0  0   7  14\n",
      "4     6180  0  0  12  28\n",
      "..     ... .. ..  ..  ..\n",
      "909  79000  0  0   1   2\n",
      "910  19169  0  0   1   0\n",
      "911  71497  0  1   0   0\n",
      "912  70309  0  0   1   6\n",
      "913  59174  0  0   1   6\n",
      "\n",
      "[914 rows x 5 columns]\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "   Class  TN  FN   FP   TP\n",
      "0    174   0   0   40  162\n",
      "1     93   1   0  285  780\n",
      "2     95   0   1  145  381\n",
      "3    173   0   2   63  203\n",
      "4     34   1   0  100  314\n",
      "5    117   0   0   58  157\n",
      "6     11   0   4  200  588\n",
      "7     26   0   4   94  293\n",
      "8     33   3   5   51  156\n",
      "9     92   1   3  257  775\n",
      "10    29   0   1   51  172\n",
      "11    90   0   1  183  511\n",
      "12   127   0   1   62  176\n",
      "13    22   1   0   93  266\n",
      "14    69   2   0  111  273\n",
      "15    96   1   3  176  547\n",
      "16   210   0   1   74  302\n",
      "17   133   0   2   94  292\n",
      "18     9   1   2  136  394\n",
      "19   145   0   0  132  390\n",
      "20    94   1   2  221  637\n",
      "21    30  24  56  321  796\n",
      "22   172   0   0   89  228\n",
      "23   141   0   2  113  406\n",
      "24    32   1   4   39  128\n",
      "25    55   1   2  189  562\n",
      "26   123   2   1   18   81\n",
      "27   130   0   0   44  152\n",
      "28    31   1   0  114  362\n",
      "29    88   1   0  141  441\n",
      "30   211   0   4  128  297\n",
      "31   139   1   1   68  190\n",
      "32    10   0   1  141  416\n",
      "33    28   0   2   96  289\n",
      "34    35   3   3   46  137\n",
      "35   124   1   2   97  305\n",
      "36   176   9  15   22   57\n",
      "37    45   1   1  172  482\n",
      "38    49   0   1  101  305\n",
      "39   178   0   1   96  206\n",
      "40   134  15  46    0   10\n",
      "41   115   3   9   13   42\n",
      "42    91   0   1   90  222\n",
      "43   120   0   1   53  153\n",
      "44   177   0   4   16   53\n",
      "45   116   1   5   30   75\n",
      "46   118   1   3   15   42\n",
      "47    25   0   1   16   24\n",
      "48   119   1   1   39   84\n",
      "49   136   3  12   13   27\n",
      "50   175   2   9   22   59\n",
      "51    27   7  19    0    0\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "    Class TN FN   FP   TP\n",
      "0     280  0  0   33   94\n",
      "1      96  1  0  157  421\n",
      "2     182  0  0   31   76\n",
      "3     279  0  0    9   32\n",
      "4     234  1  0   30  100\n",
      "..    ... .. ..  ...  ...\n",
      "194   289  0  0    4   15\n",
      "195   433  0  0    4   15\n",
      "196   291  0  0    6   10\n",
      "197   369  0  0    6   10\n",
      "198   214  0  1    3    4\n",
      "\n",
      "[199 rows x 5 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/CM.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_class_cm(\n",
    "            data_frame=df,\n",
    "            acctuals='class_acctual',\n",
    "            predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/CM.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.017166\n",
      "1   -0.011884\n",
      "2   -0.005283\n",
      "3    0.005283\n",
      "4    0.011884\n",
      "5    0.017166\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -1.000000\n",
      "1     -0.998106\n",
      "2     -0.998069\n",
      "3     -0.997372\n",
      "4     -0.997001\n",
      "         ...   \n",
      "299    0.997001\n",
      "300    0.997372\n",
      "301    0.998069\n",
      "302    0.998106\n",
      "303    1.000000\n",
      "Length: 304, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "Series([], dtype: float64)\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -1.000000\n",
      "1      -0.998047\n",
      "2      -0.997930\n",
      "3      -0.997602\n",
      "4      -0.997382\n",
      "          ...   \n",
      "1715    0.997382\n",
      "1716    0.997602\n",
      "1717    0.997930\n",
      "1718    0.998047\n",
      "1719    1.000000\n",
      "Length: 1720, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0      -1.000000\n",
      "1      -0.996324\n",
      "2      -0.996000\n",
      "3      -0.995781\n",
      "4      -0.995455\n",
      "          ...   \n",
      "3155    0.995455\n",
      "3156    0.995781\n",
      "3157    0.996000\n",
      "3158    0.996324\n",
      "3159    1.000000\n",
      "Length: 3160, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/RD.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_RD(\n",
    "            data_frame=df,\n",
    "            acctuals='class_acctual',\n",
    "            predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/RD.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RD bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.0172, -0.00572]    2\n",
      "(-0.00572, 0.00572]    2\n",
      "(0.00572, 0.0172]      2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-1.002, -0.333]     17\n",
      "(-0.333, 0.333]     270\n",
      "(0.333, 1.0]         17\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-1.002, -0.333]      80\n",
      "(-0.333, 0.333]     1560\n",
      "(0.333, 1.0]          80\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-1.002, -0.333]     238\n",
      "(-0.333, 0.333]     2684\n",
      "(0.333, 1.0]         238\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/RD_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_RD(\n",
    "            data_frame=df,\n",
    "            acctuals='class_acctual',\n",
    "            predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        # To bypass some empty matrices\n",
    "        try:\n",
    "            bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "            print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "\n",
    "            # save output to log txt\n",
    "            with open('output/RD_bucketized.txt', 'a') as f:\n",
    "                with redirect_stdout(f):\n",
    "                    print(f\"{column}\\n{bucketized_output.to_string()}\\n\")\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Difference in label rates (DLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image info](./docs/images/metrics/DAR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> DAR > -1 AND DAR < 1\n",
    "\n",
    "> DRR > -1 AND DRR < 1\n",
    "\n",
    "> DAR is the same as precision difference between the first and second classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "   class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0            1.0                    2492                1.0   \n",
      "1            1.0                    8780                1.0   \n",
      "2            1.0                    3367                1.0   \n",
      "\n",
      "   count_grouped_predictions Class  TN   FN    FP    TP  \n",
      "0                       2235   427   4   12   871  2480  \n",
      "1                       7298   426  75  193  2989  8587  \n",
      "2                       2791   413  11   34  1108  3333  \n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             1.0                      78                1.0   \n",
      "1             1.0                     761                1.0   \n",
      "2             1.0                      33                1.0   \n",
      "3             1.0                     328                1.0   \n",
      "4             1.0                      80                1.0   \n",
      "5             1.0                      21                1.0   \n",
      "6             1.0                    1005                1.0   \n",
      "7             1.0                    3058                1.0   \n",
      "8             1.0                     374                1.0   \n",
      "9             1.0                     518                1.0   \n",
      "10            1.0                    1211                1.0   \n",
      "11            1.0                     831                1.0   \n",
      "12            1.0                     290                1.0   \n",
      "13            1.0                    2322                1.0   \n",
      "14            1.0                     259                1.0   \n",
      "15            1.0                     528                1.0   \n",
      "16            1.0                     261                1.0   \n",
      "17            1.0                     507                1.0   \n",
      "18            1.0                     667                1.0   \n",
      "19            1.0                     143                1.0   \n",
      "20            1.0                     316                1.0   \n",
      "21            1.0                      12                1.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN    FP    TP  \n",
      "0                          75   177   0   0    32    78  \n",
      "1                         679   176   0   2   261   759  \n",
      "2                          32   160   0   0    14    33  \n",
      "3                         249   139   0   0   110   328  \n",
      "4                          66   138   1   0    23    80  \n",
      "5                          20   136   0   0     8    21  \n",
      "6                         922   126   1   4   348  1001  \n",
      "7                        2699   121  17  41  1078  3017  \n",
      "8                         326   116  11  26   117   348  \n",
      "9                         477   114   1   1   174   517  \n",
      "10                       1078   113   1   9   408  1202  \n",
      "11                        731   110  25  57   269   774  \n",
      "12                        145   109   0   2    85   288  \n",
      "13                       2166   108   3   9   812  2313  \n",
      "14                        240   107   0   1    98   258  \n",
      "15                        313   106   0   1   199   527  \n",
      "16                        236   105   0   2    91   259  \n",
      "17                        485   104   3   2   183   505  \n",
      "18                        627   103   2   2   212   665  \n",
      "19                        131  1011   0   1    36   142  \n",
      "20                        283  1010   0   2   100   314  \n",
      "21                         11  1002   0   0     3    12  \n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              1.0                       7                1.0   \n",
      "1              1.0                      16                1.0   \n",
      "2              1.0                       4                1.0   \n",
      "3              1.0                       2                1.0   \n",
      "4              1.0                      49                1.0   \n",
      "..             ...                     ...                ...   \n",
      "744            1.0                      22                1.0   \n",
      "745            1.0                       4                1.0   \n",
      "746            1.0                      99                1.0   \n",
      "747            1.0                       2                1.0   \n",
      "748            1.0                       8                1.0   \n",
      "\n",
      "     count_grouped_predictions  Class TN FN  FP  TP  \n",
      "0                            2   9974  0  0   2   7  \n",
      "1                            8   9949  0  0   8  16  \n",
      "2                            3   9158  0  0   1   5  \n",
      "3                            1   8705  0  0   1   3  \n",
      "4                           22   8088  0  0  10  49  \n",
      "..                         ...    ... .. ..  ..  ..  \n",
      "744                         19   1218  0  1  12  21  \n",
      "745                          1  11553  0  0   1   4  \n",
      "746                         85  11528  0  1  25  98  \n",
      "747                          1  10741  0  0   1   2  \n",
      "748                          7  10511  0  0   1   8  \n",
      "\n",
      "[749 rows x 9 columns]\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             1.0                     550                1.0   \n",
      "1             1.0                     382                1.0   \n",
      "2             1.0                     639                1.0   \n",
      "3             1.0                     780                1.0   \n",
      "4             1.0                     778                1.0   \n",
      "5             1.0                     223                1.0   \n",
      "6             1.0                     512                1.0   \n",
      "7             1.0                     396                1.0   \n",
      "8             1.0                     441                1.0   \n",
      "9             1.0                     273                1.0   \n",
      "10            1.0                     564                1.0   \n",
      "11            1.0                     306                1.0   \n",
      "12            1.0                     483                1.0   \n",
      "13            1.0                     140                1.0   \n",
      "14            1.0                     314                1.0   \n",
      "15            1.0                     161                1.0   \n",
      "16            1.0                     132                1.0   \n",
      "17            1.0                     362                1.0   \n",
      "18            1.0                     852                1.0   \n",
      "19            1.0                     173                1.0   \n",
      "20            1.0                     291                1.0   \n",
      "21            1.0                     297                1.0   \n",
      "22            1.0                      25                1.0   \n",
      "23            1.0                     266                1.0   \n",
      "24            1.0                     301                1.0   \n",
      "25            1.0                     303                1.0   \n",
      "26            1.0                     207                1.0   \n",
      "27            1.0                      57                1.0   \n",
      "28            1.0                      72                1.0   \n",
      "29            1.0                      68                1.0   \n",
      "30            1.0                     162                1.0   \n",
      "31            1.0                     205                1.0   \n",
      "32            1.0                     228                1.0   \n",
      "33            1.0                     390                1.0   \n",
      "34            1.0                     408                1.0   \n",
      "35            1.0                     191                1.0   \n",
      "36            1.0                      39                1.0   \n",
      "37            1.0                     294                1.0   \n",
      "38            1.0                     152                1.0   \n",
      "39            1.0                     177                1.0   \n",
      "40            1.0                     307                1.0   \n",
      "41            1.0                      82                1.0   \n",
      "42            1.0                     154                1.0   \n",
      "43            1.0                      85                1.0   \n",
      "44            1.0                      45                1.0   \n",
      "45            1.0                     157                1.0   \n",
      "46            1.0                      80                1.0   \n",
      "47            1.0                      51                1.0   \n",
      "48            1.0                     592                1.0   \n",
      "49            1.0                     417                1.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN   FP   TP  \n",
      "0                         446    96   1   3  176  547  \n",
      "1                         345    95   0   1  145  381  \n",
      "2                         537    94   1   2  221  637  \n",
      "3                         639    93   1   0  285  780  \n",
      "4                         694    92   1   3  257  775  \n",
      "5                         197    91   0   1   90  222  \n",
      "6                         433    90   0   1  183  511  \n",
      "7                         364     9   1   2  136  394  \n",
      "8                         400    88   1   0  141  441  \n",
      "9                         241    69   2   0  111  273  \n",
      "10                        455    55   1   2  189  562  \n",
      "11                        266    49   0   1  101  305  \n",
      "12                        427    45   1   1  172  482  \n",
      "13                        111    35   3   3   46  137  \n",
      "14                        280    34   1   0  100  314  \n",
      "15                        153    33   3   5   51  156  \n",
      "16                        110    32   1   4   39  128  \n",
      "17                        276    31   1   0  114  362  \n",
      "18                        702    30  24  56  321  796  \n",
      "19                        152    29   0   1   51  172  \n",
      "20                        259    28   0   2   96  289  \n",
      "21                        191    26   0   4   94  293  \n",
      "22                         24    25   0   1   16   24  \n",
      "23                        227    22   1   0   93  266  \n",
      "24                        258   211   0   4  128  297  \n",
      "25                        276   210   0   1   74  302  \n",
      "26                        161   178   0   1   96  206  \n",
      "27                         48   177   0   4   16   53  \n",
      "28                         44   176   9  15   22   57  \n",
      "29                         42   175   2   9   22   59  \n",
      "30                        144   174   0   0   40  162  \n",
      "31                        192   173   0   2   63  203  \n",
      "32                        196   172   0   0   89  228  \n",
      "33                        334   145   0   0  132  390  \n",
      "34                        336   141   0   2  113  406  \n",
      "35                        177   139   1   1   68  190  \n",
      "36                         24   136   3  12   13   27  \n",
      "37                        254   133   0   2   94  292  \n",
      "38                        129   130   0   0   44  152  \n",
      "39                        151   127   0   1   62  176  \n",
      "40                        273   124   1   2   97  305  \n",
      "41                         71   123   2   1   18   81  \n",
      "42                        135   120   0   1   53  153  \n",
      "43                         75   119   1   1   39   84  \n",
      "44                         42   118   1   3   15   42  \n",
      "45                        142   117   0   0   58  157  \n",
      "46                         67   116   1   5   30   75  \n",
      "47                         32   115   3   9   13   42  \n",
      "48                        416    11   0   4  200  588  \n",
      "49                        376    10   0   1  141  416  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: brand_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              1.0                     384                1.0   \n",
      "1              1.0                     421                1.0   \n",
      "2              1.0                     272                1.0   \n",
      "3              1.0                      30                1.0   \n",
      "4              1.0                      35                1.0   \n",
      "..             ...                     ...                ...   \n",
      "191            1.0                     121                1.0   \n",
      "192            1.0                      70                1.0   \n",
      "193            1.0                      79                1.0   \n",
      "194            1.0                     273                1.0   \n",
      "195            1.0                     237                1.0   \n",
      "\n",
      "     count_grouped_predictions Class TN FN   FP   TP  \n",
      "0                          320    99  1  2  142  382  \n",
      "1                          366    96  1  0  157  421  \n",
      "2                          237    95  1  1   86  271  \n",
      "3                           30    90  0  0    8   30  \n",
      "4                           31    85  0  0    5   35  \n",
      "..                         ...   ... .. ..  ...  ...  \n",
      "191                        110   123  1  0   41  121  \n",
      "192                         70   116  0  0   28   70  \n",
      "193                         59   114  3  9   16   70  \n",
      "194                        221   111  1  2   95  271  \n",
      "195                        206   108  0  1   83  236  \n",
      "\n",
      "[196 rows x 9 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/AR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_AR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/AR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.084576\n",
      "1   -0.067004\n",
      "2   -0.017572\n",
      "3    0.017572\n",
      "4    0.067004\n",
      "5    0.084576\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.954957\n",
      "1     -0.946207\n",
      "2     -0.944970\n",
      "3     -0.936207\n",
      "4     -0.927383\n",
      "         ...   \n",
      "457    0.927383\n",
      "458    0.936207\n",
      "459    0.944970\n",
      "460    0.946207\n",
      "461    0.954957\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0       -249.000000\n",
      "1       -248.800000\n",
      "2       -248.750000\n",
      "3       -248.666667\n",
      "4       -248.600000\n",
      "            ...    \n",
      "31275    248.600000\n",
      "31276    248.666667\n",
      "31277    248.750000\n",
      "31278    248.800000\n",
      "31279    249.000000\n",
      "Length: 31280, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -0.534031\n",
      "1      -0.514424\n",
      "2      -0.476740\n",
      "3      -0.460585\n",
      "4      -0.451614\n",
      "          ...   \n",
      "2247    0.451614\n",
      "2248    0.460585\n",
      "2249    0.476740\n",
      "2250    0.514424\n",
      "2251    0.534031\n",
      "Length: 2252, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0       -20.916667\n",
      "1       -20.833333\n",
      "2       -20.791667\n",
      "3       -20.777778\n",
      "4       -20.768707\n",
      "           ...    \n",
      "20173    20.768707\n",
      "20174    20.777778\n",
      "20175    20.791667\n",
      "20176    20.833333\n",
      "20177    20.916667\n",
      "Length: 20178, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DAR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DAR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DAR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAR bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.0847, -0.0282]    2\n",
      "(-0.0282, 0.0282]     2\n",
      "(0.0282, 0.0846]      2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-0.957, -0.318]     40\n",
      "(-0.318, 0.318]     382\n",
      "(0.318, 0.955]       40\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(-249.498, -83.0]      367\n",
      "(-83.0, 83.0]        30547\n",
      "(83.0, 249.0]          366\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-0.535, -0.178]     204\n",
      "(-0.178, 0.178]     1844\n",
      "(0.178, 0.534]       204\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-20.958, -6.972]      430\n",
      "(-6.972, 6.972]      19318\n",
      "(6.972, 20.917]        430\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DAR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DAR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DAR_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "   class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0            0.0                     875                0.0   \n",
      "1            0.0                    3064                0.0   \n",
      "2            0.0                    1119                0.0   \n",
      "\n",
      "   count_grouped_predictions Class  TN   FN    FP    TP  \n",
      "0                       1116   427   4   12   871  2480  \n",
      "1                       4278   426  75  193  2989  8587  \n",
      "2                       1650   413  11   34  1108  3333  \n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             0.0                      32                0.0   \n",
      "1             0.0                     261                0.0   \n",
      "2             0.0                      14                0.0   \n",
      "3             0.0                     110                0.0   \n",
      "4             0.0                      24                0.0   \n",
      "5             0.0                       8                0.0   \n",
      "6             0.0                     349                0.0   \n",
      "7             0.0                    1095                0.0   \n",
      "8             0.0                     128                0.0   \n",
      "9             0.0                     175                0.0   \n",
      "10            0.0                     409                0.0   \n",
      "11            0.0                     294                0.0   \n",
      "12            0.0                      85                0.0   \n",
      "13            0.0                     815                0.0   \n",
      "14            0.0                      98                0.0   \n",
      "15            0.0                     199                0.0   \n",
      "16            0.0                      91                0.0   \n",
      "17            0.0                     186                0.0   \n",
      "18            0.0                     214                0.0   \n",
      "19            0.0                      36                0.0   \n",
      "20            0.0                     100                0.0   \n",
      "21            0.0                       3                0.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN    FP    TP  \n",
      "0                          35   177   0   0    32    78  \n",
      "1                         341   176   0   2   261   759  \n",
      "2                          15   160   0   0    14    33  \n",
      "3                         189   139   0   0   110   328  \n",
      "4                          37   138   1   0    23    80  \n",
      "5                           9   136   0   0     8    21  \n",
      "6                         427   126   1   4   348  1001  \n",
      "7                        1396   121  17  41  1078  3017  \n",
      "8                         139   116  11  26   117   348  \n",
      "9                         214   114   1   1   174   517  \n",
      "10                        532   113   1   9   408  1202  \n",
      "11                        312   110  25  57   269   774  \n",
      "12                        228   109   0   2    85   288  \n",
      "13                        959   108   3   9   812  2313  \n",
      "14                        116   107   0   1    98   258  \n",
      "15                        413   106   0   1   199   527  \n",
      "16                        114   105   0   2    91   259  \n",
      "17                        203   104   3   2   183   505  \n",
      "18                        250   103   2   2   212   665  \n",
      "19                         47  1011   0   1    36   142  \n",
      "20                        131  1010   0   2   100   314  \n",
      "21                          4  1002   0   0     3    12  \n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              0.0                       2                0.0   \n",
      "1              0.0                       1                0.0   \n",
      "2              0.0                       8                0.0   \n",
      "3              0.0                       1                0.0   \n",
      "4              0.0                       1                0.0   \n",
      "..             ...                     ...                ...   \n",
      "540            0.0                      12                0.0   \n",
      "541            0.0                       1                0.0   \n",
      "542            0.0                      25                0.0   \n",
      "543            0.0                       1                0.0   \n",
      "544            0.0                       1                0.0   \n",
      "\n",
      "     count_grouped_predictions  Class TN FN  FP  TP  \n",
      "0                            7   9974  0  0   2   7  \n",
      "1                            1   9966  0  0   1   0  \n",
      "2                           16   9949  0  0   8  16  \n",
      "3                            1   9617  0  0   1   0  \n",
      "4                            1   8632  0  0   1   0  \n",
      "..                         ...    ... .. ..  ..  ..  \n",
      "540                         14   1218  0  1  12  21  \n",
      "541                          4  11553  0  0   1   4  \n",
      "542                         38  11528  0  1  25  98  \n",
      "543                          2  10741  0  0   1   2  \n",
      "544                          2  10511  0  0   1   8  \n",
      "\n",
      "[545 rows x 9 columns]\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             0.0                     177                0.0   \n",
      "1             0.0                     145                0.0   \n",
      "2             0.0                     222                0.0   \n",
      "3             0.0                     286                0.0   \n",
      "4             0.0                     258                0.0   \n",
      "5             0.0                      90                0.0   \n",
      "6             0.0                     183                0.0   \n",
      "7             0.0                     137                0.0   \n",
      "8             0.0                     142                0.0   \n",
      "9             0.0                     113                0.0   \n",
      "10            0.0                     190                0.0   \n",
      "11            0.0                     101                0.0   \n",
      "12            0.0                     173                0.0   \n",
      "13            0.0                      49                0.0   \n",
      "14            0.0                     101                0.0   \n",
      "15            0.0                      54                0.0   \n",
      "16            0.0                      40                0.0   \n",
      "17            0.0                     115                0.0   \n",
      "18            0.0                     345                0.0   \n",
      "19            0.0                      51                0.0   \n",
      "20            0.0                      96                0.0   \n",
      "21            0.0                      94                0.0   \n",
      "22            0.0                      16                0.0   \n",
      "23            0.0                      94                0.0   \n",
      "24            0.0                     128                0.0   \n",
      "25            0.0                      74                0.0   \n",
      "26            0.0                      96                0.0   \n",
      "27            0.0                      16                0.0   \n",
      "28            0.0                      31                0.0   \n",
      "29            0.0                      24                0.0   \n",
      "30            0.0                      40                0.0   \n",
      "31            0.0                      63                0.0   \n",
      "32            0.0                      89                0.0   \n",
      "33            0.0                     132                0.0   \n",
      "34            0.0                     113                0.0   \n",
      "35            0.0                      69                0.0   \n",
      "36            0.0                      16                0.0   \n",
      "37            0.0                      15                0.0   \n",
      "38            0.0                      94                0.0   \n",
      "39            0.0                      44                0.0   \n",
      "40            0.0                      62                0.0   \n",
      "41            0.0                      98                0.0   \n",
      "42            0.0                      20                0.0   \n",
      "43            0.0                      53                0.0   \n",
      "44            0.0                      40                0.0   \n",
      "45            0.0                      16                0.0   \n",
      "46            0.0                      58                0.0   \n",
      "47            0.0                      31                0.0   \n",
      "48            0.0                      16                0.0   \n",
      "49            0.0                     200                0.0   \n",
      "50            0.0                     141                0.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN   FP   TP  \n",
      "0                         277    96   1   3  176  547  \n",
      "1                         181    95   0   1  145  381  \n",
      "2                         321    94   1   2  221  637  \n",
      "3                         426    93   1   0  285  780  \n",
      "4                         338    92   1   3  257  775  \n",
      "5                         115    91   0   1   90  222  \n",
      "6                         261    90   0   1  183  511  \n",
      "7                         166     9   1   2  136  394  \n",
      "8                         182    88   1   0  141  441  \n",
      "9                         143    69   2   0  111  273  \n",
      "10                        296    55   1   2  189  562  \n",
      "11                        140    49   0   1  101  305  \n",
      "12                        227    45   1   1  172  482  \n",
      "13                         72    35   3   3   46  137  \n",
      "14                        134    34   1   0  100  314  \n",
      "15                         54    33   3   5   51  156  \n",
      "16                         57    32   1   4   39  128  \n",
      "17                        200    31   1   0  114  362  \n",
      "18                        415    30  24  56  321  796  \n",
      "19                         71    29   0   1   51  172  \n",
      "20                        126    28   0   2   96  289  \n",
      "21                        196    26   0   4   94  293  \n",
      "22                         16    25   0   1   16   24  \n",
      "23                        132    22   1   0   93  266  \n",
      "24                        167   211   0   4  128  297  \n",
      "25                        100   210   0   1   74  302  \n",
      "26                        141   178   0   1   96  206  \n",
      "27                         21   177   0   4   16   53  \n",
      "28                         35   176   9  15   22   57  \n",
      "29                         39   175   2   9   22   59  \n",
      "30                         58   174   0   0   40  162  \n",
      "31                         74   173   0   2   63  203  \n",
      "32                        121   172   0   0   89  228  \n",
      "33                        188   145   0   0  132  390  \n",
      "34                        183   141   0   2  113  406  \n",
      "35                         81   139   1   1   68  190  \n",
      "36                         16   136   3  12   13   27  \n",
      "37                         10   134  15  46    0   10  \n",
      "38                        132   133   0   2   94  292  \n",
      "39                         67   130   0   0   44  152  \n",
      "40                         87   127   0   1   62  176  \n",
      "41                        129   124   1   2   97  305  \n",
      "42                         28   123   2   1   18   81  \n",
      "43                         71   120   0   1   53  153  \n",
      "44                         48   119   1   1   39   84  \n",
      "45                         15   118   1   3   15   42  \n",
      "46                         73   117   0   0   58  157  \n",
      "47                         38   116   1   5   30   75  \n",
      "48                         23   115   3   9   13   42  \n",
      "49                        372    11   0   4  200  588  \n",
      "50                        181    10   0   1  141  416  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: brand_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              0.0                     143                0.0   \n",
      "1              0.0                     158                0.0   \n",
      "2              0.0                      87                0.0   \n",
      "3              0.0                       8                0.0   \n",
      "4              0.0                       5                0.0   \n",
      "..             ...                     ...                ...   \n",
      "189            0.0                      42                0.0   \n",
      "190            0.0                      28                0.0   \n",
      "191            0.0                      19                0.0   \n",
      "192            0.0                      96                0.0   \n",
      "193            0.0                      83                0.0   \n",
      "\n",
      "     count_grouped_predictions Class TN FN   FP   TP  \n",
      "0                          204    99  1  2  142  382  \n",
      "1                          212    96  1  0  157  421  \n",
      "2                          120    95  1  1   86  271  \n",
      "3                            8    90  0  0    8   30  \n",
      "4                            9    85  0  0    5   35  \n",
      "..                         ...   ... .. ..  ...  ...  \n",
      "189                         52   123  1  0   41  121  \n",
      "190                         28   116  0  0   28   70  \n",
      "191                         27   114  3  9   16   70  \n",
      "192                        145   111  1  2   95  271  \n",
      "193                        113   108  0  1   83  236  \n",
      "\n",
      "[194 rows x 9 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/RR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_RR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/RR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.008487\n",
      "1   -0.006336\n",
      "2   -0.002152\n",
      "3    0.002152\n",
      "4    0.006336\n",
      "5    0.008487\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.034200\n",
      "1     -0.033742\n",
      "2     -0.033272\n",
      "3     -0.033115\n",
      "4     -0.032815\n",
      "         ...   \n",
      "105    0.032815\n",
      "106    0.033115\n",
      "107    0.033272\n",
      "108    0.033742\n",
      "109    0.034200\n",
      "Length: 110, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0      -8.000000\n",
      "1      -7.998536\n",
      "2      -7.997664\n",
      "3      -7.997076\n",
      "4      -7.993939\n",
      "          ...   \n",
      "1525    7.993939\n",
      "1526    7.997076\n",
      "1527    7.997664\n",
      "1528    7.998536\n",
      "1529    8.000000\n",
      "Length: 1530, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0     -0.204545\n",
      "1     -0.203105\n",
      "2     -0.202981\n",
      "3     -0.202683\n",
      "4     -0.202348\n",
      "         ...   \n",
      "695    0.202348\n",
      "696    0.202683\n",
      "697    0.202981\n",
      "698    0.203105\n",
      "699    0.204545\n",
      "Length: 700, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0      -0.473684\n",
      "1      -0.470952\n",
      "2      -0.470559\n",
      "3      -0.469778\n",
      "4      -0.469465\n",
      "          ...   \n",
      "1309    0.469465\n",
      "1310    0.469778\n",
      "1311    0.470559\n",
      "1312    0.470952\n",
      "1313    0.473684\n",
      "Length: 1314, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DRR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DRR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DRR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRR bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.0085, -0.00283]    2\n",
      "(-0.00283, 0.00283]    2\n",
      "(0.00283, 0.00849]     2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-0.0343, -0.0114]    24\n",
      "(-0.0114, 0.0114]     62\n",
      "(0.0114, 0.0342]      24\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(-8.016, -2.667]      39\n",
      "(-2.667, 2.667]     1452\n",
      "(2.667, 8.0]          39\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-0.205, -0.0682]     70\n",
      "(-0.0682, 0.0682]    560\n",
      "(0.0682, 0.205]       70\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-0.475, -0.158]      66\n",
      "(-0.158, 0.158]     1182\n",
      "(0.158, 0.474]        66\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/DRR_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_DRR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/DRR_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Accuracy DIfference (AD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image info](./docs/images/metrics/AD.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[SOURCE](https://pages.awscloud.com/rs/112-TZM-766/images/Amazon.AI.Fairness.and.Explainability.Whitepaper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CHARACTERISTICS OF METRIC:\n",
    "> Unbounded metric\n",
    "\n",
    "> Care needed when FN = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "   class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0            1.0                    2492                1.0   \n",
      "1            1.0                    8780                1.0   \n",
      "2            1.0                    3367                1.0   \n",
      "\n",
      "   count_grouped_predictions Class  TN   FN    FP    TP  \n",
      "0                       2235   427   4   12   871  2480  \n",
      "1                       7298   426  75  193  2989  8587  \n",
      "2                       2791   413  11   34  1108  3333  \n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             1.0                      78                1.0   \n",
      "1             1.0                     761                1.0   \n",
      "2             1.0                      33                1.0   \n",
      "3             1.0                     328                1.0   \n",
      "4             1.0                      80                1.0   \n",
      "5             1.0                      21                1.0   \n",
      "6             1.0                    1005                1.0   \n",
      "7             1.0                    3058                1.0   \n",
      "8             1.0                     374                1.0   \n",
      "9             1.0                     518                1.0   \n",
      "10            1.0                    1211                1.0   \n",
      "11            1.0                     831                1.0   \n",
      "12            1.0                     290                1.0   \n",
      "13            1.0                    2322                1.0   \n",
      "14            1.0                     259                1.0   \n",
      "15            1.0                     528                1.0   \n",
      "16            1.0                     261                1.0   \n",
      "17            1.0                     507                1.0   \n",
      "18            1.0                     667                1.0   \n",
      "19            1.0                     143                1.0   \n",
      "20            1.0                     316                1.0   \n",
      "21            1.0                      12                1.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN    FP    TP  \n",
      "0                          75   177   0   0    32    78  \n",
      "1                         679   176   0   2   261   759  \n",
      "2                          32   160   0   0    14    33  \n",
      "3                         249   139   0   0   110   328  \n",
      "4                          66   138   1   0    23    80  \n",
      "5                          20   136   0   0     8    21  \n",
      "6                         922   126   1   4   348  1001  \n",
      "7                        2699   121  17  41  1078  3017  \n",
      "8                         326   116  11  26   117   348  \n",
      "9                         477   114   1   1   174   517  \n",
      "10                       1078   113   1   9   408  1202  \n",
      "11                        731   110  25  57   269   774  \n",
      "12                        145   109   0   2    85   288  \n",
      "13                       2166   108   3   9   812  2313  \n",
      "14                        240   107   0   1    98   258  \n",
      "15                        313   106   0   1   199   527  \n",
      "16                        236   105   0   2    91   259  \n",
      "17                        485   104   3   2   183   505  \n",
      "18                        627   103   2   2   212   665  \n",
      "19                        131  1011   0   1    36   142  \n",
      "20                        283  1010   0   2   100   314  \n",
      "21                         11  1002   0   0     3    12  \n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              1.0                       7                1.0   \n",
      "1              1.0                      16                1.0   \n",
      "2              1.0                       4                1.0   \n",
      "3              1.0                       2                1.0   \n",
      "4              1.0                      49                1.0   \n",
      "..             ...                     ...                ...   \n",
      "744            1.0                      22                1.0   \n",
      "745            1.0                       4                1.0   \n",
      "746            1.0                      99                1.0   \n",
      "747            1.0                       2                1.0   \n",
      "748            1.0                       8                1.0   \n",
      "\n",
      "     count_grouped_predictions  Class TN FN  FP  TP  \n",
      "0                            2   9974  0  0   2   7  \n",
      "1                            8   9949  0  0   8  16  \n",
      "2                            3   9158  0  0   1   5  \n",
      "3                            1   8705  0  0   1   3  \n",
      "4                           22   8088  0  0  10  49  \n",
      "..                         ...    ... .. ..  ..  ..  \n",
      "744                         19   1218  0  1  12  21  \n",
      "745                          1  11553  0  0   1   4  \n",
      "746                         85  11528  0  1  25  98  \n",
      "747                          1  10741  0  0   1   2  \n",
      "748                          7  10511  0  0   1   8  \n",
      "\n",
      "[749 rows x 9 columns]\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             1.0                     550                1.0   \n",
      "1             1.0                     382                1.0   \n",
      "2             1.0                     639                1.0   \n",
      "3             1.0                     780                1.0   \n",
      "4             1.0                     778                1.0   \n",
      "5             1.0                     223                1.0   \n",
      "6             1.0                     512                1.0   \n",
      "7             1.0                     396                1.0   \n",
      "8             1.0                     441                1.0   \n",
      "9             1.0                     273                1.0   \n",
      "10            1.0                     564                1.0   \n",
      "11            1.0                     306                1.0   \n",
      "12            1.0                     483                1.0   \n",
      "13            1.0                     140                1.0   \n",
      "14            1.0                     314                1.0   \n",
      "15            1.0                     161                1.0   \n",
      "16            1.0                     132                1.0   \n",
      "17            1.0                     362                1.0   \n",
      "18            1.0                     852                1.0   \n",
      "19            1.0                     173                1.0   \n",
      "20            1.0                     291                1.0   \n",
      "21            1.0                     297                1.0   \n",
      "22            1.0                      25                1.0   \n",
      "23            1.0                     266                1.0   \n",
      "24            1.0                     301                1.0   \n",
      "25            1.0                     303                1.0   \n",
      "26            1.0                     207                1.0   \n",
      "27            1.0                      57                1.0   \n",
      "28            1.0                      72                1.0   \n",
      "29            1.0                      68                1.0   \n",
      "30            1.0                     162                1.0   \n",
      "31            1.0                     205                1.0   \n",
      "32            1.0                     228                1.0   \n",
      "33            1.0                     390                1.0   \n",
      "34            1.0                     408                1.0   \n",
      "35            1.0                     191                1.0   \n",
      "36            1.0                      39                1.0   \n",
      "37            1.0                     294                1.0   \n",
      "38            1.0                     152                1.0   \n",
      "39            1.0                     177                1.0   \n",
      "40            1.0                     307                1.0   \n",
      "41            1.0                      82                1.0   \n",
      "42            1.0                     154                1.0   \n",
      "43            1.0                      85                1.0   \n",
      "44            1.0                      45                1.0   \n",
      "45            1.0                     157                1.0   \n",
      "46            1.0                      80                1.0   \n",
      "47            1.0                      51                1.0   \n",
      "48            1.0                     592                1.0   \n",
      "49            1.0                     417                1.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN   FP   TP  \n",
      "0                         446    96   1   3  176  547  \n",
      "1                         345    95   0   1  145  381  \n",
      "2                         537    94   1   2  221  637  \n",
      "3                         639    93   1   0  285  780  \n",
      "4                         694    92   1   3  257  775  \n",
      "5                         197    91   0   1   90  222  \n",
      "6                         433    90   0   1  183  511  \n",
      "7                         364     9   1   2  136  394  \n",
      "8                         400    88   1   0  141  441  \n",
      "9                         241    69   2   0  111  273  \n",
      "10                        455    55   1   2  189  562  \n",
      "11                        266    49   0   1  101  305  \n",
      "12                        427    45   1   1  172  482  \n",
      "13                        111    35   3   3   46  137  \n",
      "14                        280    34   1   0  100  314  \n",
      "15                        153    33   3   5   51  156  \n",
      "16                        110    32   1   4   39  128  \n",
      "17                        276    31   1   0  114  362  \n",
      "18                        702    30  24  56  321  796  \n",
      "19                        152    29   0   1   51  172  \n",
      "20                        259    28   0   2   96  289  \n",
      "21                        191    26   0   4   94  293  \n",
      "22                         24    25   0   1   16   24  \n",
      "23                        227    22   1   0   93  266  \n",
      "24                        258   211   0   4  128  297  \n",
      "25                        276   210   0   1   74  302  \n",
      "26                        161   178   0   1   96  206  \n",
      "27                         48   177   0   4   16   53  \n",
      "28                         44   176   9  15   22   57  \n",
      "29                         42   175   2   9   22   59  \n",
      "30                        144   174   0   0   40  162  \n",
      "31                        192   173   0   2   63  203  \n",
      "32                        196   172   0   0   89  228  \n",
      "33                        334   145   0   0  132  390  \n",
      "34                        336   141   0   2  113  406  \n",
      "35                        177   139   1   1   68  190  \n",
      "36                         24   136   3  12   13   27  \n",
      "37                        254   133   0   2   94  292  \n",
      "38                        129   130   0   0   44  152  \n",
      "39                        151   127   0   1   62  176  \n",
      "40                        273   124   1   2   97  305  \n",
      "41                         71   123   2   1   18   81  \n",
      "42                        135   120   0   1   53  153  \n",
      "43                         75   119   1   1   39   84  \n",
      "44                         42   118   1   3   15   42  \n",
      "45                        142   117   0   0   58  157  \n",
      "46                         67   116   1   5   30   75  \n",
      "47                         32   115   3   9   13   42  \n",
      "48                        416    11   0   4  200  588  \n",
      "49                        376    10   0   1  141  416  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: brand_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              1.0                     384                1.0   \n",
      "1              1.0                     421                1.0   \n",
      "2              1.0                     272                1.0   \n",
      "3              1.0                      30                1.0   \n",
      "4              1.0                      35                1.0   \n",
      "..             ...                     ...                ...   \n",
      "191            1.0                     121                1.0   \n",
      "192            1.0                      70                1.0   \n",
      "193            1.0                      79                1.0   \n",
      "194            1.0                     273                1.0   \n",
      "195            1.0                     237                1.0   \n",
      "\n",
      "     count_grouped_predictions Class TN FN   FP   TP  \n",
      "0                          320    99  1  2  142  382  \n",
      "1                          366    96  1  0  157  421  \n",
      "2                          237    95  1  1   86  271  \n",
      "3                           30    90  0  0    8   30  \n",
      "4                           31    85  0  0    5   35  \n",
      "..                         ...   ... .. ..  ...  ...  \n",
      "191                        110   123  1  0   41  121  \n",
      "192                         70   116  0  0   28   70  \n",
      "193                         59   114  3  9   16   70  \n",
      "194                        221   111  1  2   95  271  \n",
      "195                        206   108  0  1   83  236  \n",
      "\n",
      "[196 rows x 9 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/AR.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_AR(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/AR.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.014089\n",
      "1   -0.007681\n",
      "2   -0.006408\n",
      "3    0.006408\n",
      "4    0.007681\n",
      "5    0.014089\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.097872\n",
      "1     -0.091168\n",
      "2     -0.090909\n",
      "3     -0.089778\n",
      "4     -0.084861\n",
      "         ...   \n",
      "457    0.084861\n",
      "458    0.089778\n",
      "459    0.090909\n",
      "460    0.091168\n",
      "461    0.097872\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0       -1.000000\n",
      "1       -0.916667\n",
      "2       -0.909091\n",
      "3       -0.900000\n",
      "4       -0.888889\n",
      "           ...   \n",
      "20915    0.888889\n",
      "20916    0.900000\n",
      "20917    0.909091\n",
      "20918    0.916667\n",
      "20919    1.000000\n",
      "Length: 20920, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -0.268271\n",
      "1      -0.256526\n",
      "2      -0.255606\n",
      "3      -0.233816\n",
      "4      -0.230056\n",
      "          ...   \n",
      "2445    0.230056\n",
      "2446    0.233816\n",
      "2447    0.255606\n",
      "2448    0.256526\n",
      "2449    0.268271\n",
      "Length: 2450, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0       -0.428571\n",
      "1       -0.399160\n",
      "2       -0.388889\n",
      "3       -0.375940\n",
      "4       -0.375000\n",
      "           ...   \n",
      "21415    0.375000\n",
      "21416    0.375940\n",
      "21417    0.388889\n",
      "21418    0.399160\n",
      "21419    0.428571\n",
      "Length: 21420, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/AD.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_AD(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/AD.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "   class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0            0.0                     875                0.0   \n",
      "1            0.0                    3064                0.0   \n",
      "2            0.0                    1119                0.0   \n",
      "\n",
      "   count_grouped_predictions Class  TN   FN    FP    TP  \n",
      "0                       1116   427   4   12   871  2480  \n",
      "1                       4278   426  75  193  2989  8587  \n",
      "2                       1650   413  11   34  1108  3333  \n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             0.0                      32                0.0   \n",
      "1             0.0                     261                0.0   \n",
      "2             0.0                      14                0.0   \n",
      "3             0.0                     110                0.0   \n",
      "4             0.0                      24                0.0   \n",
      "5             0.0                       8                0.0   \n",
      "6             0.0                     349                0.0   \n",
      "7             0.0                    1095                0.0   \n",
      "8             0.0                     128                0.0   \n",
      "9             0.0                     175                0.0   \n",
      "10            0.0                     409                0.0   \n",
      "11            0.0                     294                0.0   \n",
      "12            0.0                      85                0.0   \n",
      "13            0.0                     815                0.0   \n",
      "14            0.0                      98                0.0   \n",
      "15            0.0                     199                0.0   \n",
      "16            0.0                      91                0.0   \n",
      "17            0.0                     186                0.0   \n",
      "18            0.0                     214                0.0   \n",
      "19            0.0                      36                0.0   \n",
      "20            0.0                     100                0.0   \n",
      "21            0.0                       3                0.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN    FP    TP  \n",
      "0                          35   177   0   0    32    78  \n",
      "1                         341   176   0   2   261   759  \n",
      "2                          15   160   0   0    14    33  \n",
      "3                         189   139   0   0   110   328  \n",
      "4                          37   138   1   0    23    80  \n",
      "5                           9   136   0   0     8    21  \n",
      "6                         427   126   1   4   348  1001  \n",
      "7                        1396   121  17  41  1078  3017  \n",
      "8                         139   116  11  26   117   348  \n",
      "9                         214   114   1   1   174   517  \n",
      "10                        532   113   1   9   408  1202  \n",
      "11                        312   110  25  57   269   774  \n",
      "12                        228   109   0   2    85   288  \n",
      "13                        959   108   3   9   812  2313  \n",
      "14                        116   107   0   1    98   258  \n",
      "15                        413   106   0   1   199   527  \n",
      "16                        114   105   0   2    91   259  \n",
      "17                        203   104   3   2   183   505  \n",
      "18                        250   103   2   2   212   665  \n",
      "19                         47  1011   0   1    36   142  \n",
      "20                        131  1010   0   2   100   314  \n",
      "21                          4  1002   0   0     3    12  \n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              0.0                       2                0.0   \n",
      "1              0.0                       1                0.0   \n",
      "2              0.0                       8                0.0   \n",
      "3              0.0                       1                0.0   \n",
      "4              0.0                       1                0.0   \n",
      "..             ...                     ...                ...   \n",
      "540            0.0                      12                0.0   \n",
      "541            0.0                       1                0.0   \n",
      "542            0.0                      25                0.0   \n",
      "543            0.0                       1                0.0   \n",
      "544            0.0                       1                0.0   \n",
      "\n",
      "     count_grouped_predictions  Class TN FN  FP  TP  \n",
      "0                            7   9974  0  0   2   7  \n",
      "1                            1   9966  0  0   1   0  \n",
      "2                           16   9949  0  0   8  16  \n",
      "3                            1   9617  0  0   1   0  \n",
      "4                            1   8632  0  0   1   0  \n",
      "..                         ...    ... .. ..  ..  ..  \n",
      "540                         14   1218  0  1  12  21  \n",
      "541                          4  11553  0  0   1   4  \n",
      "542                         38  11528  0  1  25  98  \n",
      "543                          2  10741  0  0   1   2  \n",
      "544                          2  10511  0  0   1   8  \n",
      "\n",
      "[545 rows x 9 columns]\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "    class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0             0.0                     177                0.0   \n",
      "1             0.0                     145                0.0   \n",
      "2             0.0                     222                0.0   \n",
      "3             0.0                     286                0.0   \n",
      "4             0.0                     258                0.0   \n",
      "5             0.0                      90                0.0   \n",
      "6             0.0                     183                0.0   \n",
      "7             0.0                     137                0.0   \n",
      "8             0.0                     142                0.0   \n",
      "9             0.0                     113                0.0   \n",
      "10            0.0                     190                0.0   \n",
      "11            0.0                     101                0.0   \n",
      "12            0.0                     173                0.0   \n",
      "13            0.0                      49                0.0   \n",
      "14            0.0                     101                0.0   \n",
      "15            0.0                      54                0.0   \n",
      "16            0.0                      40                0.0   \n",
      "17            0.0                     115                0.0   \n",
      "18            0.0                     345                0.0   \n",
      "19            0.0                      51                0.0   \n",
      "20            0.0                      96                0.0   \n",
      "21            0.0                      94                0.0   \n",
      "22            0.0                      16                0.0   \n",
      "23            0.0                      94                0.0   \n",
      "24            0.0                     128                0.0   \n",
      "25            0.0                      74                0.0   \n",
      "26            0.0                      96                0.0   \n",
      "27            0.0                      16                0.0   \n",
      "28            0.0                      31                0.0   \n",
      "29            0.0                      24                0.0   \n",
      "30            0.0                      40                0.0   \n",
      "31            0.0                      63                0.0   \n",
      "32            0.0                      89                0.0   \n",
      "33            0.0                     132                0.0   \n",
      "34            0.0                     113                0.0   \n",
      "35            0.0                      69                0.0   \n",
      "36            0.0                      16                0.0   \n",
      "37            0.0                      15                0.0   \n",
      "38            0.0                      94                0.0   \n",
      "39            0.0                      44                0.0   \n",
      "40            0.0                      62                0.0   \n",
      "41            0.0                      98                0.0   \n",
      "42            0.0                      20                0.0   \n",
      "43            0.0                      53                0.0   \n",
      "44            0.0                      40                0.0   \n",
      "45            0.0                      16                0.0   \n",
      "46            0.0                      58                0.0   \n",
      "47            0.0                      31                0.0   \n",
      "48            0.0                      16                0.0   \n",
      "49            0.0                     200                0.0   \n",
      "50            0.0                     141                0.0   \n",
      "\n",
      "    count_grouped_predictions Class  TN  FN   FP   TP  \n",
      "0                         277    96   1   3  176  547  \n",
      "1                         181    95   0   1  145  381  \n",
      "2                         321    94   1   2  221  637  \n",
      "3                         426    93   1   0  285  780  \n",
      "4                         338    92   1   3  257  775  \n",
      "5                         115    91   0   1   90  222  \n",
      "6                         261    90   0   1  183  511  \n",
      "7                         166     9   1   2  136  394  \n",
      "8                         182    88   1   0  141  441  \n",
      "9                         143    69   2   0  111  273  \n",
      "10                        296    55   1   2  189  562  \n",
      "11                        140    49   0   1  101  305  \n",
      "12                        227    45   1   1  172  482  \n",
      "13                         72    35   3   3   46  137  \n",
      "14                        134    34   1   0  100  314  \n",
      "15                         54    33   3   5   51  156  \n",
      "16                         57    32   1   4   39  128  \n",
      "17                        200    31   1   0  114  362  \n",
      "18                        415    30  24  56  321  796  \n",
      "19                         71    29   0   1   51  172  \n",
      "20                        126    28   0   2   96  289  \n",
      "21                        196    26   0   4   94  293  \n",
      "22                         16    25   0   1   16   24  \n",
      "23                        132    22   1   0   93  266  \n",
      "24                        167   211   0   4  128  297  \n",
      "25                        100   210   0   1   74  302  \n",
      "26                        141   178   0   1   96  206  \n",
      "27                         21   177   0   4   16   53  \n",
      "28                         35   176   9  15   22   57  \n",
      "29                         39   175   2   9   22   59  \n",
      "30                         58   174   0   0   40  162  \n",
      "31                         74   173   0   2   63  203  \n",
      "32                        121   172   0   0   89  228  \n",
      "33                        188   145   0   0  132  390  \n",
      "34                        183   141   0   2  113  406  \n",
      "35                         81   139   1   1   68  190  \n",
      "36                         16   136   3  12   13   27  \n",
      "37                         10   134  15  46    0   10  \n",
      "38                        132   133   0   2   94  292  \n",
      "39                         67   130   0   0   44  152  \n",
      "40                         87   127   0   1   62  176  \n",
      "41                        129   124   1   2   97  305  \n",
      "42                         28   123   2   1   18   81  \n",
      "43                         71   120   0   1   53  153  \n",
      "44                         48   119   1   1   39   84  \n",
      "45                         15   118   1   3   15   42  \n",
      "46                         73   117   0   0   58  157  \n",
      "47                         38   116   1   5   30   75  \n",
      "48                         23   115   3   9   13   42  \n",
      "49                        372    11   0   4  200  588  \n",
      "50                        181    10   0   1  141  416  \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: brand_id\n",
      "\n",
      "     class_acctual  count_grouped_acctuals  predict_automatch  \\\n",
      "0              0.0                     143                0.0   \n",
      "1              0.0                     158                0.0   \n",
      "2              0.0                      87                0.0   \n",
      "3              0.0                       8                0.0   \n",
      "4              0.0                       5                0.0   \n",
      "..             ...                     ...                ...   \n",
      "189            0.0                      42                0.0   \n",
      "190            0.0                      28                0.0   \n",
      "191            0.0                      19                0.0   \n",
      "192            0.0                      96                0.0   \n",
      "193            0.0                      83                0.0   \n",
      "\n",
      "     count_grouped_predictions Class TN FN   FP   TP  \n",
      "0                          204    99  1  2  142  382  \n",
      "1                          212    96  1  0  157  421  \n",
      "2                          120    95  1  1   86  271  \n",
      "3                            8    90  0  0    8   30  \n",
      "4                            9    85  0  0    5   35  \n",
      "..                         ...   ... .. ..  ...  ...  \n",
      "189                         52   123  1  0   41  121  \n",
      "190                         28   116  0  0   28   70  \n",
      "191                         27   114  3  9   16   70  \n",
      "192                        145   111  1  2   95  271  \n",
      "193                        113   108  0  1   83  236  \n",
      "\n",
      "[194 rows x 9 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/A.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_A(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/A.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "0   -0.014089\n",
      "1   -0.007681\n",
      "2   -0.006408\n",
      "3    0.006408\n",
      "4    0.007681\n",
      "5    0.014089\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "0     -0.097872\n",
      "1     -0.091168\n",
      "2     -0.090909\n",
      "3     -0.089778\n",
      "4     -0.084861\n",
      "         ...   \n",
      "457    0.084861\n",
      "458    0.089778\n",
      "459    0.090909\n",
      "460    0.091168\n",
      "461    0.097872\n",
      "Length: 462, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "0       -1.000000\n",
      "1       -0.916667\n",
      "2       -0.909091\n",
      "3       -0.900000\n",
      "4       -0.888889\n",
      "           ...   \n",
      "20915    0.888889\n",
      "20916    0.900000\n",
      "20917    0.909091\n",
      "20918    0.916667\n",
      "20919    1.000000\n",
      "Length: 20920, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "0      -0.268271\n",
      "1      -0.256526\n",
      "2      -0.255606\n",
      "3      -0.233816\n",
      "4      -0.230056\n",
      "          ...   \n",
      "2445    0.230056\n",
      "2446    0.233816\n",
      "2447    0.255606\n",
      "2448    0.256526\n",
      "2449    0.268271\n",
      "Length: 2450, dtype: float64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "0       -0.428571\n",
      "1       -0.399160\n",
      "2       -0.388889\n",
      "3       -0.375940\n",
      "4       -0.375000\n",
      "           ...   \n",
      "21415    0.375000\n",
      "21416    0.375940\n",
      "21417    0.388889\n",
      "21418    0.399160\n",
      "21419    0.428571\n",
      "Length: 21420, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/AD.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_AD(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        output = pd.Series(output)\n",
    "        print(f\"COLUMN: {column}\\n\\n{output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/AD.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN: prod_gr_id\n",
      "\n",
      "(-0.0141, -0.0047]    3\n",
      "(-0.0047, 0.0047]     0\n",
      "(0.0047, 0.0141]      3\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: country_id_n\n",
      "\n",
      "(-0.0981, -0.0326]     83\n",
      "(-0.0326, 0.0326]     296\n",
      "(0.0326, 0.0979]       83\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: delivery_type_id\n",
      "\n",
      "(-1.002, -0.333]     1161\n",
      "(-0.333, 0.333]     18597\n",
      "(0.333, 1.0]         1162\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: retailer_id\n",
      "\n",
      "(-0.269, -0.0894]     179\n",
      "(-0.0894, 0.0894]    2092\n",
      "(0.0894, 0.268]       179\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "COLUMN: brand_id\n",
      "\n",
      "(-0.429, -0.143]     1493\n",
      "(-0.143, 0.143]     18435\n",
      "(0.143, 0.429]       1492\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_exclude = [\n",
    "    'period_end_date',\n",
    "    'translated_when',\n",
    "    'if_data_corrected',\n",
    "    'freq_id',\n",
    "    'predict_automatch',\n",
    "    'class_acctual'\n",
    "]\n",
    "\n",
    "# clear a file\n",
    "with open('output/AD_bucketized.txt', 'a') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "# loop over columns and aggregate\n",
    "for column in df.columns:\n",
    "    if column not in columns_to_exclude:\n",
    "        output = get_AD(\n",
    "            data_frame=df,\n",
    "            column_to_count_acctuals='class_acctual',\n",
    "            column_to_count_predictions='predict_automatch',\n",
    "            column_to_group_by=column\n",
    "        )\n",
    "        \n",
    "        bucketized_output = pd.cut(output, bins=3).value_counts()\n",
    "        print(f\"COLUMN: {column}\\n\\n{bucketized_output}\\n\\n\")\n",
    "        \n",
    "        # save output to log txt\n",
    "        with open('output/AD_bucketized.txt', 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                print(f\"{column}\\n{bucketized_output.to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### CONCLUSIONS:\n",
    "\n",
    "> TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
